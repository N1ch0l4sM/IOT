{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b379823",
   "metadata": {},
   "source": [
    "# Notebook para análise exploratória dos dados climáticos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1d0decb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Dict\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c1aace87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para limpar os dados\n",
    "def clean_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Aplica limpeza e renomeação de colunas.\"\"\"\n",
    "    df = df.drop(columns=[\n",
    "        'pressure_in', 'temperature_fahrenheit', 'wind_mph',\n",
    "        'precip_in', 'feels_like_fahrenheit', 'visibility_miles', 'gust_mph'\n",
    "    ])\n",
    "    df = df.rename(columns={\n",
    "        'temperature_celsius': 'temperature',\n",
    "        'pressure_mb': 'pressure',\n",
    "        'wind_kph': 'wind_speed',\n",
    "        'precip_mm': 'precipitation',\n",
    "        'last_updated': 'recorded_at'\n",
    "    })\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4b725f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Função para engenharia de features\n",
    "def feature_engineering(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Cria novas features a partir dos dados existentes.\"\"\"\n",
    "    df['recorded_at'] = pd.to_datetime(df['recorded_at'])\n",
    "    df['hour'] = df['recorded_at'].dt.hour\n",
    "    df['day_of_week'] = df['recorded_at'].dt.dayofweek\n",
    "    df['month'] = df['recorded_at'].dt.month\n",
    "    df['dew_point'] = _calculate_dew_point(df['temperature'], df['humidity'])\n",
    "    df['pressure_tendency'] = df['pressure'].diff().fillna(0)\n",
    "    df['temp_humidity_interaction'] = df['temperature'] * df['humidity']\n",
    "    df['wind_pressure_interaction'] = df['wind_speed'] * df['pressure']\n",
    "    df['will_rain'] = (df['precipitation'] > 0).astype(int)\n",
    "    return df\n",
    "\n",
    "# Função auxiliar para calcular o ponto de orvalho\n",
    "def _calculate_dew_point(temp: pd.Series, humidity: pd.Series) -> pd.Series:\n",
    "    \"\"\"Calcula o ponto de orvalho.\"\"\"\n",
    "    a, b = 17.27, 237.7\n",
    "    alpha = ((a * temp) / (b + temp)) + np.log(humidity / 100)\n",
    "    return (b * alpha) / (a - alpha)\n",
    "\n",
    "# Função para preparar as features\n",
    "def prepare_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Seleciona e prepara as features para o modelo.\"\"\"\n",
    "    feature_columns = [\n",
    "        'temperature', 'humidity', 'pressure', 'wind_speed',\n",
    "        'dew_point', 'pressure_tendency',\n",
    "        'temp_humidity_interaction', 'wind_pressure_interaction',\n",
    "        'hour', 'day_of_week', 'month'\n",
    "    ]\n",
    "    return df[[col for col in feature_columns if col in df.columns]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f7f4a3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _evaluate_model(model, X_test: pd.DataFrame, y_test: pd.Series) -> Dict:\n",
    "    \"\"\"Avalia performance do modelo\"\"\"\n",
    "    # Predições\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Métricas\n",
    "    auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    \n",
    "    # Cross-validation\n",
    "    cv_scores = cross_val_score(model, X_test, y_test, cv=5, scoring='roc_auc')\n",
    "    \n",
    "    # Relatório de classificação\n",
    "    class_report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    \n",
    "    # Matriz de confusão\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    metrics = {\n",
    "        'auc': auc,\n",
    "        'cv_mean': cv_scores.mean(),\n",
    "        'cv_std': cv_scores.std(),\n",
    "        'precision': class_report['1']['precision'],\n",
    "        'recall': class_report['1']['recall'],\n",
    "        'f1_score': class_report['1']['f1-score'],\n",
    "        'accuracy': class_report['accuracy'],\n",
    "        'confusion_matrix': conf_matrix.tolist()\n",
    "    }\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "02149122",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Função para treinar o modelo\n",
    "def train_model(df: pd.DataFrame, target_column: str = 'will_rain') -> Dict:\n",
    "    \"\"\"Treina o modelo de previsão.\"\"\"\n",
    "    X = prepare_features(df)\n",
    "    y = df[target_column]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "    model = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('classifier', RandomForestClassifier(\n",
    "            n_estimators=100, max_depth=10, random_state=42, n_jobs=-1\n",
    "        ))\n",
    "    ])\n",
    "    model.fit(X_train, y_train) \n",
    "    # Avaliar modelo\n",
    "    metrics = _evaluate_model(model, X_test, y_test)\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901b288e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'accuracy': 0.7760227547809248,\n",
      "    'auc': 0.840698049704051,\n",
      "    'confusion_matrix': [[9549, 1413], [2288, 3274]],\n",
      "    'cv_mean': np.float64(0.8347517801209173),\n",
      "    'cv_std': np.float64(0.009116744803299473),\n",
      "    'f1_score': 0.6388915991804078,\n",
      "    'precision': 0.6985278429699168,\n",
      "    'recall': 0.5886371808701906}\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('/home/nicholas/projects/IOT/data/raw/GlobalWeatherRepository.csv')\n",
    "# Limpar os dados\n",
    "df_clean = clean_data(df)\n",
    "\n",
    "# Aplicar engenharia de features\n",
    "df_features = feature_engineering(df_clean)\n",
    "\n",
    "# Treinar o modelo\n",
    "results = train_model(df_features)\n",
    "\n",
    "# Exibir a acurácia do modelo\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "pp.pprint(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "109cbd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "def get_feature_importance(model, df) -> pd.DataFrame:\n",
    "    \"\"\"Retorna importância das features\"\"\"        \n",
    "    # Obter importância do Random Forest\n",
    "    importance = model.named_steps['classifier'].feature_importances_\n",
    "    \n",
    "    # Criar DataFrame com importância\n",
    "    importance_df = pd.DataFrame({\n",
    "        'feature': df.feature_columns,\n",
    "        'importance': importance\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    return importance_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
